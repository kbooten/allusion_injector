{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62048fb8",
   "metadata": {},
   "source": [
    "# Mining Wikipedia for Semantic Relations\n",
    "\n",
    "I define some functions to extract some semantic relations from Wikipedia text.  Specifically, they are relations that could be useful for crafting \"automatic allusions\"---i.e., given a `target word` such as `\"multitudinous\"`, return a snippet of text containing an old proper noun, such as `\"as Ashurbanipal's army\"`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5247d30",
   "metadata": {},
   "source": [
    "## Mining ⛏️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740edd08",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90220b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed91f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def test_contiguous(numbers):\n",
    "    \"\"\"\n",
    "    just make sure that ints are contiguous\n",
    "    useful for making sure a span of text isn't missing any words\n",
    "    \"\"\"\n",
    "    for en,n in enumerate(numbers[:-1]):\n",
    "        if n+1!=numbers[en+1]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print(test_contiguous([123,124,125,126]))\n",
    "print(test_contiguous([123,20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d849a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moatt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Moatt, of, Carthage, ,]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_chunk(word,tempspacy):\n",
    "    \"\"\"\n",
    "    get all ancestors of a word\n",
    "    exclude bits that are connected by appos dependency\n",
    "    \"\"\"\n",
    "    descendants = [i for i in tempspacy if (word.is_ancestor(i) or i==word)]\n",
    "    to_ban = [i for i in descendants if (i.dep_ in [\"appos\"] and i!=word)]\n",
    "    descendants_valid = [i for i in descendants if i not in to_ban]\n",
    "    descendants_valid = [i for i in descendants_valid if not any([banned.is_ancestor(i) for banned in to_ban])]\n",
    "    return descendants_valid\n",
    "\n",
    "s = \"Moatt of Carthage, a wise king, is very tired.\"\n",
    "sp = nlp(s)\n",
    "print(sp[0])\n",
    "get_chunk(sp[0],sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de20cb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rclip(fragment,bad_ending_pos=[\"PUNCT\",\"SPACE\"]):#ok_ending_pos=[\"NOUN\",\"PROPN\"]):\n",
    "    \"\"\"\n",
    "    remove everything from the right of a spacy sequence if doesn't end correctly\n",
    "    \"\"\"\n",
    "    while len(fragment)>0 and (fragment[-1].pos_ in bad_ending_pos and fragment[-1].text!=\")\"):\n",
    "            fragment.pop()\n",
    "    return fragment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4710ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Moatt, of, Carthage]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rclip(get_chunk(sp[0],sp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd3b687",
   "metadata": {},
   "source": [
    "### Functions for Mining Relations from Text Parsed with `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21fba8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'of',\n",
       "  'target': 'library',\n",
       "  'other_words': 'semi|-|ugly',\n",
       "  'allusion': 'of the cat of Alexandria',\n",
       "  'allusion2': None,\n",
       "  'target_pos': 'NOUN'},\n",
       " {'type': 'of',\n",
       "  'target': 'cat',\n",
       "  'other_words': '',\n",
       "  'allusion': 'of Alexandria',\n",
       "  'allusion2': None,\n",
       "  'target_pos': 'NOUN'},\n",
       " {'type': 'of',\n",
       "  'target': 'library',\n",
       "  'other_words': '',\n",
       "  'allusion': 'of Alexandria',\n",
       "  'allusion2': None,\n",
       "  'target_pos': 'PROPN'},\n",
       " {'type': 'of',\n",
       "  'target': 'scales',\n",
       "  'other_words': 'shining',\n",
       "  'allusion': 'of Agoatus',\n",
       "  'allusion2': None,\n",
       "  'target_pos': 'PROPN'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def noun_of_nounphrase(tempspacy):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    to_return = []\n",
    "    for t in tempspacy:\n",
    "        if t.head.text.lower()==\"of\" and t.pos_ in [\"NOUN\",\"PROPN\"]:\n",
    "            fragment = rclip([i for i in tempspacy if (t.head.is_ancestor(i))])\n",
    "            fragment_pos = [i.pos_ for i in fragment]\n",
    "            fragment_indices = [i.i for i in fragment]\n",
    "            if test_contiguous(fragment_indices):\n",
    "                if \"PROPN\" in fragment_pos:\n",
    "                    to_return.append({\n",
    "                        \"type\":\"of\",\n",
    "                        \"target\":str(t.head.head).lower(),\n",
    "                        #\"target_original\":str(t.head.head),\n",
    "                        \"other_words\":\"|\".join([child.text.lower() for child in t.head.head.children if child.dep_ in ['amod',\"conj\",\"advmod\"]]),\n",
    "                        \"allusion\":\"of \"+str(tempspacy[fragment_indices[0]:fragment_indices[-1]+1]),\n",
    "                        \"allusion2\":None,\n",
    "                        \"target_pos\":t.head.head.pos_,\n",
    "\n",
    "                    })\n",
    "    return to_return\n",
    "\n",
    "noun_of_nounphrase(nlp(\"Beyond the old cat's stinky legs and ugly face.  The semi-ugly library of the cat of Alexandria.  And there was a Library of Alexandria. The cat's beautiful felt. A ball of yarn. The Shining Scales of Agoatus.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "596f26f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'v2np',\n",
       "  'target': 'hurt',\n",
       "  'other_words': 'friend',\n",
       "  'allusion': 'Ashurbanurpal hurt my friend',\n",
       "  'allusion2': 'Ashurbanurpal',\n",
       "  'target_pos': 'VERB'},\n",
       " {'type': 'v2np',\n",
       "  'target': 'advance',\n",
       "  'other_words': 'first|south|secure',\n",
       "  'allusion': \"Ashurbanipal's army first advanced south and secured the city of Der\",\n",
       "  'allusion2': \"Ashurbanipal's army\",\n",
       "  'target_pos': 'VERB'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def verb2np(tempspacy):\n",
    "    to_return = []\n",
    "    for t in tempspacy:\n",
    "        if t.dep_==\"nsubj\":\n",
    "            subtree = list(t.head.subtree)\n",
    "            span = tempspacy[subtree[0].i:subtree[-1].i+1]\n",
    "            if span[0].dep_==\"mark\":\n",
    "                span = tempspacy[subtree[1].i:subtree[-1].i+1]\n",
    "            fragment = [i for i in tempspacy if (t.is_ancestor(i) or i==t)]\n",
    "            fragment_pos = [i.pos_ for i in fragment]\n",
    "            fragment_indices = [i.i for i in fragment]\n",
    "            if test_contiguous(fragment_indices):\n",
    "                if \"PROPN\" in fragment_pos:\n",
    "                    if t.head.lemma_ not in [\"be\"]: # boring\n",
    "                        to_return.append({\"type\":\"v2np\",\n",
    "                                          \"target\":t.head.lemma_,\n",
    "                                          \"other_words\":\"|\".join([child.lemma_ for child in t.head.children if child.dep_ in [\"dobj\",\"conj\",\"advmod\",\"prt\"]]),\n",
    "                                          \"allusion\":str(span),\n",
    "                                          \"allusion2\":str(tempspacy[fragment_indices[0]:fragment_indices[-1]+1]),\n",
    "                                          \"target_pos\":t.head.pos_,\n",
    "                                         })\n",
    "    return to_return\n",
    "\n",
    "verb2np(nlp(\"I have heard that Ashurbanurpal hurt my friend. I have heard a rumor that Ashurbanipal's army first advanced south and secured the city of Der, and there were people there\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8287bb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'rebellious',\n",
       "  'allusion': 'the rebellious, stinky friends of Azerooit and his merciless ilk',\n",
       "  'type': 'adj2np',\n",
       "  'allusion2': None,\n",
       "  'other_words': None,\n",
       "  'target_pos': 'ADJ'},\n",
       " {'target': 'stinky',\n",
       "  'allusion': 'the rebellious, stinky friends of Azerooit and his merciless ilk',\n",
       "  'type': 'adj2np',\n",
       "  'allusion2': None,\n",
       "  'other_words': None,\n",
       "  'target_pos': 'ADJ'},\n",
       " {'target': 'shining',\n",
       "  'allusion': 'the shining scales of Aotis',\n",
       "  'type': 'adj2np',\n",
       "  'allusion2': None,\n",
       "  'other_words': None,\n",
       "  'target_pos': 'ADJ'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def adj_to_noun_phrase(tempspacy):\n",
    "    to_return = []\n",
    "    for t in tempspacy:\n",
    "        if t.dep_==\"amod\":\n",
    "            if \"neg\" not in [c.dep_ for c in t.children]:\n",
    "                if (t.head.pos_==\"NOUN\"):\n",
    "                    #fragment = rclip([i for i in tempspacy if (t.head.is_ancestor(i) or i==t.head)])\n",
    "                    fragment = rclip(get_chunk(t.head,tempspacy))\n",
    "                    fragment_pos = [i.pos_ for i in fragment]\n",
    "                    fragment_indices = [i.i for i in fragment]\n",
    "                    if test_contiguous(fragment_indices):\n",
    "                        if \"PROPN\" in fragment_pos:\n",
    "                            to_return.append({\n",
    "                                \"target\":str(t).lower(),\n",
    "                                \"allusion\":str(tempspacy[fragment_indices[0]:fragment_indices[-1]+1]),\n",
    "                                \"type\":\"adj2np\",\n",
    "                                \"allusion2\":None,\n",
    "                                \"other_words\":None,\n",
    "                                \"target_pos\":\"ADJ\",\n",
    "                            })\n",
    "    return to_return\n",
    "        \n",
    "adj_to_noun_phrase(nlp(\"I saw the rebellious, stinky friends of Azerooit and his merciless ilk, a bad team.  And I saw the shining scales of Aotis.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e831e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_or_acomp_relation(tempspacy):\n",
    "    to_return = []\n",
    "    for t in tempspacy: \n",
    "        if (t.dep_==\"nsubj\" and t.head.pos_==\"AUX\"):  ## looking for nouns that are in nsubj relationship to aux verb\n",
    "            if \"neg\" not in [i.dep_ for i in t.head.children]: ## exclude negatives\n",
    "                attrs = [ch for ch in [tok for tok in tempspacy if tok.head==t.head] if ch.dep_ in [\"attr\",\"acomp\"]]\n",
    "                if attrs!=[]: ## if there is at least 1 attr\n",
    "                    attr = attrs[0] ## just deal with the 0th one\n",
    "                    attr_or_acomp = attr.dep_\n",
    "                    ## get the noun ph\n",
    "                    #np_fragment = [i for i in tempspacy if (t.is_ancestor(i) or i==t)]\n",
    "                    np_fragment = rclip(get_chunk(t,tempspacy))\n",
    "                    np_fragment_pos = [i.pos_ for i in np_fragment]\n",
    "                    np_fragment_indices = [i.i for i in np_fragment]\n",
    "                    noun_phrase = str(tempspacy[np_fragment_indices[0]:np_fragment_indices[-1]+1])\n",
    "                    if \"PROPN\" in np_fragment_pos:     \n",
    "                        ## get attr phrase\n",
    "                        #attr_fragment = [i for i in tempspacy if (attr.is_ancestor(i) or i==attr)]\n",
    "                        attr_fragment = rclip((get_chunk(attr,tempspacy)))\n",
    "                        attr_fragment_indices = [i.i for i in attr_fragment]\n",
    "                        attr_phrase = str(tempspacy[attr_fragment_indices[0]:attr_fragment_indices[-1]+1])\n",
    "                        ## get attr phrase simple\n",
    "                        valid_deps = [\"det\",\"amod\"]\n",
    "                        simple_fragment = [i for i in tempspacy if ((i.head==attr and i.dep_ in valid_deps) or i==attr)]\n",
    "                        simple_fragment_indices = [i.i for i in simple_fragment]\n",
    "                        simple_phrase = str(tempspacy[simple_fragment_indices[0]:simple_fragment_indices[-1]+1])\n",
    "                        if test_contiguous(np_fragment_indices) and test_contiguous(attr_fragment_indices):\n",
    "                            for n in [w for w in simple_fragment if w.pos_ in [\"NOUN\",\"ADJ\"]]:\n",
    "                                to_return.append({\n",
    "                                    \"type\":attr_or_acomp,\n",
    "                                    \"allusion\":noun_phrase,\n",
    "                                    \"target\":n.lemma_,\n",
    "                                    \"allusion2\":simple_phrase,\n",
    "                                    \"other_words\":\"|\".join([child.text.lower() for child in n.children if child.dep_ in ['amod']]),\n",
    "                                    \"target_pos\":n.pos_\n",
    "                                })\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7714e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'acomp',\n",
       "  'allusion': 'John',\n",
       "  'target': 'uick',\n",
       "  'allusion2': 'uick',\n",
       "  'other_words': '',\n",
       "  'target_pos': 'ADJ'},\n",
       " {'type': 'attr',\n",
       "  'allusion': 'The feet of the Big King',\n",
       "  'target': 'simple',\n",
       "  'allusion2': 'a simple nomadic people',\n",
       "  'other_words': '',\n",
       "  'target_pos': 'ADJ'},\n",
       " {'type': 'attr',\n",
       "  'allusion': 'The feet of the Big King',\n",
       "  'target': 'nomadic',\n",
       "  'allusion2': 'a simple nomadic people',\n",
       "  'other_words': '',\n",
       "  'target_pos': 'ADJ'},\n",
       " {'type': 'attr',\n",
       "  'allusion': 'The feet of the Big King',\n",
       "  'target': 'people',\n",
       "  'allusion2': 'a simple nomadic people',\n",
       "  'other_words': 'simple|nomadic',\n",
       "  'target_pos': 'NOUN'},\n",
       " {'type': 'attr',\n",
       "  'allusion': 'the Dull Forest',\n",
       "  'target': 'stupid',\n",
       "  'allusion2': 'a stupid place',\n",
       "  'other_words': '',\n",
       "  'target_pos': 'ADJ'},\n",
       " {'type': 'attr',\n",
       "  'allusion': 'the Dull Forest',\n",
       "  'target': 'place',\n",
       "  'allusion2': 'a stupid place',\n",
       "  'other_words': 'stupid',\n",
       "  'target_pos': 'NOUN'},\n",
       " {'type': 'attr',\n",
       "  'allusion': 'Mausoolus',\n",
       "  'target': 'wise',\n",
       "  'allusion2': 'a wise king',\n",
       "  'other_words': '',\n",
       "  'target_pos': 'ADJ'},\n",
       " {'type': 'attr',\n",
       "  'allusion': 'Mausoolus',\n",
       "  'target': 'king',\n",
       "  'allusion2': 'a wise king',\n",
       "  'other_words': 'wise',\n",
       "  'target_pos': 'NOUN'},\n",
       " {'type': 'attr',\n",
       "  'allusion': 'John',\n",
       "  'target': 'big',\n",
       "  'allusion2': 'a big lawyer',\n",
       "  'other_words': '',\n",
       "  'target_pos': 'ADJ'},\n",
       " {'type': 'attr',\n",
       "  'allusion': 'John',\n",
       "  'target': 'lawyer',\n",
       "  'allusion2': 'a big lawyer',\n",
       "  'other_words': 'big',\n",
       "  'target_pos': 'NOUN'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_or_acomp_relation(nlp(\"John is uick to speak. A mind is a terrible thing to puree. The feet of the Big King were a simple nomadic people who moved through the earth and ate things, and the Dull Forest was a stupid place where old people went. Mausoolus was a wise king of bitter sadness, a good person.  John was a big lawyer.  Mausoolus of Xeria was going to the store.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b606481a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'appos',\n",
       "  'allusion': ' King Mausaillus of Carthage',\n",
       "  'allusion2': 'a wise and fat king',\n",
       "  'target': 'wise',\n",
       "  'other_words': 'wise|fat',\n",
       "  'target_pos': 'ADJ'},\n",
       " {'type': 'appos',\n",
       "  'allusion': ' King Mausaillus of Carthage',\n",
       "  'allusion2': 'a wise and fat king',\n",
       "  'target': 'fat',\n",
       "  'other_words': 'wise|fat',\n",
       "  'target_pos': 'ADJ'},\n",
       " {'type': 'appos',\n",
       "  'allusion': ' King Mausaillus of Carthage',\n",
       "  'allusion2': 'a wise and fat king',\n",
       "  'target': 'king',\n",
       "  'other_words': 'wise|fat',\n",
       "  'target_pos': 'NOUN'},\n",
       " {'type': 'appos',\n",
       "  'allusion': 'The old King Mausoolaic of Wales',\n",
       "  'allusion2': 'a wise and smelly king',\n",
       "  'target': 'wise',\n",
       "  'other_words': 'wise|smelly',\n",
       "  'target_pos': 'ADJ'},\n",
       " {'type': 'appos',\n",
       "  'allusion': 'The old King Mausoolaic of Wales',\n",
       "  'allusion2': 'a wise and smelly king',\n",
       "  'target': 'smelly',\n",
       "  'other_words': 'wise|smelly',\n",
       "  'target_pos': 'ADJ'},\n",
       " {'type': 'appos',\n",
       "  'allusion': 'The old King Mausoolaic of Wales',\n",
       "  'allusion2': 'a wise and smelly king',\n",
       "  'target': 'king',\n",
       "  'other_words': 'wise|smelly',\n",
       "  'target_pos': 'NOUN'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def appos_relation(tempspacy):\n",
    "    to_return = []\n",
    "    for t in tempspacy:\n",
    "        if t.dep_==\"appos\":\n",
    "            appos_fragment = get_chunk(t,tempspacy) ##[i for i in tempspacy if (t.is_ancestor(i) or i==t)]\n",
    "            appos_fragment_indices = [i.i for i in appos_fragment]\n",
    "            appos_phrase = str(tempspacy[appos_fragment_indices[0]:appos_fragment_indices[-1]+1])\n",
    "            ## get the noun ph\n",
    "            noun_or_proper_noun = t.head\n",
    "            valid_deps = ['compound']\n",
    "            np_fragment = rclip(get_chunk(noun_or_proper_noun,tempspacy))#\n",
    "            np_fragment_pos = [i.pos_ for i in np_fragment]\n",
    "            np_fragment_indices = [i.i for i in np_fragment]\n",
    "            noun_phrase = str(tempspacy[np_fragment_indices[0]:np_fragment_indices[-1]+1])\n",
    "            if \"PROPN\" in np_fragment_pos:    \n",
    "                if test_contiguous(np_fragment_indices) and test_contiguous(appos_fragment_indices):\n",
    "                    for n in [w for w in appos_fragment if w.pos_ in [\"NOUN\",\"ADJ\"]]:\n",
    "                        to_return.append({\n",
    "                            \"type\":\"appos\",\n",
    "                            \"allusion\":noun_phrase,\n",
    "                            \"allusion2\":appos_phrase,\n",
    "                            \"target\":n.lemma_,\n",
    "                            \"other_words\":\"|\".join([w.lemma_ for w in appos_fragment if w.pos_==\"ADJ\"]),\n",
    "                            \"target_pos\":n.pos_,\n",
    "                        })                   \n",
    "    return to_return\n",
    "\n",
    "appos_relation(nlp(\" King Mausaillus of Carthage, a wise and fat king, is my friend. Mausoolus was going to the store. The old King Mausoolaic of Wales, a wise and smelly king, is my friend.\"))#ppos_relation(nlp(\"King Mausaillus of Carthage, a wise person, is my friend. Mausoolus was going to the store. The old King Mausoolaic of Wales, a wise king, is my friend.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68ba57d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'compound',\n",
       "  'allusion': 'Norbertine',\n",
       "  'allusion2': None,\n",
       "  'target': 'lace',\n",
       "  'other_words': None,\n",
       "  'target_pos': 'PROPN'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def noun_to_compound(tempspacy):\n",
    "    to_return = []\n",
    "    for t in tempspacy:\n",
    "        if (t.pos_==\"PROPN\" and t.head.pos_==\"NOUN\" and t.dep_==\"compound\"):\n",
    "            to_return.append({\n",
    "                            \"type\":\"compound\",\n",
    "                            \"allusion\":str(t),\n",
    "                            \"allusion2\":None,\n",
    "                            \"target\":t.head.lemma_,\n",
    "                            \"other_words\":None,\n",
    "                            \"target_pos\":t.pos_,\n",
    "                        })     \n",
    "    return to_return\n",
    "\n",
    "noun_to_compound(nlp(\"The Norbertine lace was on my feet.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dd1adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mining_funcs = [\n",
    "    noun_of_nounphrase,\n",
    "    verb2np,\n",
    "    adj_to_noun_phrase,\n",
    "    attr_or_acomp_relation,\n",
    "    appos_relation,\n",
    "    noun_to_compound,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a3dc86",
   "metadata": {},
   "source": [
    "## Wikipedia Article Tester\n",
    "\n",
    "I want to focus on things from Wikipedia that are old.  I will use some gnarly regexes to test whether some section of a Wikipedia text contains references to dates in the 19th century or prior and none from later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dd93e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75d8407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_stuff_regex = r'\\b(?:in|from|c\\.|year|by|since|circa) ?(?:late|early)? ?(?:\\d{3}|1[0-7]\\d\\d)\\b|\\d+ [ab]\\.?[dc]\\b|\\b(?:[1-8]|1[0-8])(?:st|nd|th) centur\\w+\\b|\\b(?!tw)(?!ninetee)[a-z]+(?:th|nd|st) centur\\w+\\b|\\b\\d{3,4}\\b ?- ?\\b(?:\\d{3}|1[0-7]\\d\\d)\\b|\\((?:\\d{3}|1[0-7]\\d\\d)\\b\\)|\\b(?:(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug)[a-z.]*|spring|summer|fall|winter),? (?:of )?(?:\\d{3}|1[0-7]\\d\\d)\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceefc59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff_regex = r'\\b(?:in|from|c\\.|year|by|since|circa) ?(?:late|early)? ?(?:1[89]|2\\d)\\d\\d\\b|\\d+ a\\.?d\\b|\\b(?:19|2\\d)(?:st|nd|th) centur\\w+\\b|\\b(?:tw|ninet)[a-z-]+(?:th|nd|st) centur\\w+\\b|\\b\\d{3,4}\\b ?- ?\\b(?:\\d{3}|1[0-8]\\d\\d)\\b|\\((?:1[89]|2\\d)\\d\\d\\b\\)|\\b(?:(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug)[a-z.]*|spring|summer|fall|winter),? (?:of )?(?:1[89]|2\\d)\\d\\d\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c2c578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"\"\"\n",
    "(c. 334 – c. 2602 BC)\n",
    "18th century\n",
    "20th century\n",
    "2nd century\n",
    "first century\n",
    "ninth century\n",
    "nineteeth century\n",
    "twentieth century\n",
    "from 1923\n",
    "from 1520\n",
    "(119)\n",
    "(1953)\n",
    "(1834)\n",
    "1995\n",
    "the year 1895\n",
    "in late 234\n",
    "in late 1943\n",
    "in early 1734\n",
    "\n",
    "June, 1924\n",
    "July of 2345\n",
    "June, 1892\n",
    "June, 234l234\n",
    "\n",
    "spring of 1233\n",
    "\n",
    "by 23445\n",
    "c.234 \n",
    "c. 1234\n",
    "1523-1934\n",
    "234\n",
    "1523453245\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb2b6821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c. 334',\n",
       " '18th century',\n",
       " '2nd century',\n",
       " 'first century',\n",
       " 'ninth century',\n",
       " 'from 1520',\n",
       " '(119)',\n",
       " 'in late 234',\n",
       " 'in early 1734',\n",
       " 'spring of 1233',\n",
       " 'c.234',\n",
       " 'c. 1234']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(old_stuff_regex,test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "927ebad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c. 2602',\n",
       " '20th century',\n",
       " 'nineteeth century',\n",
       " 'twentieth century',\n",
       " 'from 1923',\n",
       " '(1953)',\n",
       " '(1834)',\n",
       " 'year 1895',\n",
       " 'in late 1943',\n",
       " 'June, 1924',\n",
       " 'July of 2345',\n",
       " 'June, 1892']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(new_stuff_regex,test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84de67f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time_of_full_text(text,times_more=5):\n",
    "    \"\"\"\n",
    "    makes sure proper ratio of olds/new \n",
    "    \"\"\"\n",
    "    olds = re.findall(old_stuff_regex,text,flags=re.I)\n",
    "    news = re.findall(new_stuff_regex,text,flags=re.I)\n",
    "    if len(olds)>len(news)*times_more:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4547ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time_of_section(text):\n",
    "    olds = re.findall(old_stuff_regex,text,flags=re.I)\n",
    "    news = re.findall(new_stuff_regex,text,flags=re.I)\n",
    "    if len(olds)>0:\n",
    "        if len(news)==0:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aea53b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_time_of_section(\"in the 2nd CENTuRY \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7241fb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_time_of_section(\"in 1923 and the 2nd century\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9480a0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90575867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Lincoln took executive control of the war and shaped the Union military strategy.      sdfl;kasdf\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_wiki_text(text):\n",
    "    text = re.sub(r\"\\'\\'\",'',text) ## links\n",
    "    text = re.sub(r\"poly[ \\d]+\",\"\",text) ## ?\n",
    "    text = re.sub(r\"=+[^=]+=+\\n\",\" \",text) ## section headings\n",
    "    text = re.sub(r\"\\|alt=.+\\n\",\" \",text) ## alt text\n",
    "    text = text.rstrip(r\"\\n\")\n",
    "    return text\n",
    "\n",
    "clean_wiki_text('====Union military strategy====\\nLincoln took executive control of the war and shaped the Union military strategy.   |alt=Large group of people\\n  sdfl;kasdf\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6b29ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48661063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm wiki.db ## just re-initialize each time this notebook runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd473673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "connection = sqlite3.connect(\"wiki.db\")\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3941f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7faa8a1428f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"CREATE TABLE allusions (target TEXT, type TEXT, allusion TEXT, allusion2 TEXT, other_words TEXT, target_pos TEXT, entry TEXT, id NUMBER)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a6af59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_db(data):\n",
    "    sql = \"INSERT INTO allusions(target,type,allusion,allusion2,other_words,target_pos,entry,id) VALUES(?,?,?,?,?,?,?,?)\"  \n",
    "    for d in data:\n",
    "        #print(d.keys())\n",
    "        task = (d['target'],d['type'],d['allusion'],d['allusion2'],d['other_words'],d['target_pos'],d['entry'],d['id'])\n",
    "        ## replace empty strings with None\n",
    "        task = tuple(t if t!=\"\" else None for t in task)\n",
    "        #print(task)\n",
    "        cursor.execute(sql,task)\n",
    "        connection.commit()\n",
    "#         for k in d:\n",
    "#             print(k,d[k])\n",
    "            #task = (k[])\n",
    "            #cur.execute(sql, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86f0c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a59ebfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_of_full_text_for_time_test(article):\n",
    "    \"\"\"\n",
    "    returns most of article text as single string, trying to get rid of bibliography, etc.\n",
    "    this output is meant to be test\n",
    "    \"\"\"\n",
    "    bad_words = ['reference','cite','note','see also','source','adapt','popular culture','biblio','links']\n",
    "    ok_sections = [section_text for section_title,section_text in zip(article['section_titles'][:-2], article['section_texts']) if any([bw in section_title.lower() for bw in bad_words])==False]\n",
    "    full_text = \"\\n\\n\".join(ok_sections)\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61e38302",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 48min 59s, sys: 23min 45s, total: 4h 12min 44s\n",
      "Wall time: 4h 35min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# c=0\n",
    "# max_n = 100\n",
    "\n",
    "idnum = 0\n",
    "\n",
    "prob_of_processing_article = 1.0 \n",
    "\n",
    "with utils.open('enwiki-latest.json.gz', 'rb') as f:\n",
    "    for line in f:\n",
    "        if random.random()<prob_of_processing_article:\n",
    "            article = json.loads(line)\n",
    "            full_text = get_part_of_full_text_for_time_test(article)\n",
    "            if test_time_of_full_text(full_text):\n",
    "                for section_title, section_text in zip(article['section_titles'][:-2], article['section_texts'][:2]):\n",
    "                    text = section_text.strip()\n",
    "                    if test_time_of_section(text):              \n",
    "                        text = clean_wiki_text(text)\n",
    "                        ok_sents = [s for s in text.split(\"\\n\\n\") if (len(s)>=300 and s[-1]==\".\")]\n",
    "                        for oks in ok_sents:\n",
    "                            spacied = nlp(oks)\n",
    "                            for func in mining_funcs:\n",
    "                                try:\n",
    "                                    results = func(spacied)\n",
    "                                    [r.update({\"entry\":article['title']}) for r in results] ## just update all the dicts\n",
    "                                    for r in results:\n",
    "                                        r.update({\"id\":idnum})\n",
    "                                        idnum+=1\n",
    "                                    push_to_db(results)\n",
    "                                except:\n",
    "                                    pass\n",
    "#         if c==max_n:\n",
    "#             break\n",
    "#         c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9956321f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('smile',\n",
       "  'of',\n",
       "  'of the Canaanite deity El',\n",
       "  None,\n",
       "  'benevolent',\n",
       "  'NOUN',\n",
       "  'Isaac',\n",
       "  19340),\n",
       " ('smile',\n",
       "  'of',\n",
       "  'of the Canaanite deity El',\n",
       "  None,\n",
       "  'benevolent',\n",
       "  'NOUN',\n",
       "  'Isaac',\n",
       "  19341),\n",
       " ('smile', 'compound', 'Samuel', None, None, 'PROPN', 'Jakob Abbadie', 21559),\n",
       " ('smile',\n",
       "  'v2np',\n",
       "  'Musashi just smiled.',\n",
       "  'Musashi',\n",
       "  'just',\n",
       "  'VERB',\n",
       "  'Sasaki Kojirō',\n",
       "  230500),\n",
       " ('smile',\n",
       "  'v2np',\n",
       "  'Captain Glass to smile pleasantly',\n",
       "  'Captain Glass',\n",
       "  'pleasantly',\n",
       "  'VERB',\n",
       "  'Capture of Guam',\n",
       "  456054),\n",
       " ('smile',\n",
       "  'v2np',\n",
       "  'Dante to smile',\n",
       "  'Dante',\n",
       "  None,\n",
       "  'VERB',\n",
       "  'Belacqua',\n",
       "  784686),\n",
       " ('smile',\n",
       "  'v2np',\n",
       "  'Maurecia celebrates, Ron is not smiling.',\n",
       "  'Ron',\n",
       "  None,\n",
       "  'VERB',\n",
       "  'Wayside School Beneath the Cloud of Doom',\n",
       "  2116326)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_db(target):\n",
    "    cursor.execute(\"SELECT * FROM allusions WHERE target=?\", (target,))\n",
    "    rows = cursor.fetchall()\n",
    "    return rows\n",
    "\n",
    "query_db(\"smile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f643b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp wiki.db wiki_to_use.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa3765",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wiki",
   "language": "python",
   "name": "wiki"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
